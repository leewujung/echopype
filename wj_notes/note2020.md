# Echopype Dev Notes


## 2020-02-01
Stuff to fix:
- `ping_time` is not encoded correctly, now it's in float64 and not datetime64[ns]
- move `calc_sent_signal` outside of `calibrate` to be a separate method in `model/ek80.py`
- update `calc_range` to work with BB data

Found out:
- `delta = 1 / 1.5e6` in `calc_sent_signal` is hard-coded according to line 49 of `EK80ReadRawFiles_rev.m`



## 2020-02-04
Update docs and make a new release. Items to be included are:
- splitting data with different range_bin lengths to different files with names part01, part02, etc.
- pad NaN when range_bin lengths are different among frequency channels
- calibrate and MVBS handling for padded frequency channels
- allow user to feed in environmental parameters for calibration
- doc: make it explicit py38 is needed for creating environment
- beta support for Zarr

Before OSM another release should be added, with the following added functions:
- allow over0writing existing nc file
- save generated files at user-specified path
- simple viz function to plot echogram in EK500 colormap and magma


## 2020-02-10 to 2020-02-16
Note updates:
- [x] usage of user-defined env parameters
- [x] take outÂ batch converter
- [x] example outputs for data with different range_bin lengths (across channel, across ping)
- [x] put the below into doc:
		```python
		e_data = EchoData(nc_path)
		e_data.calibrate(save=True, save_path='lha.nc')
		08:23:06  saving calibrated Sv to ./echopype/test_data/ek60/lha.nc
		e_data = EchoData(nc_path)
		e_data.calibrate(save=True, save_path='./echopype/test_data/ek60/fhdjkflha.nc')
		08:23:21  saving calibrated Sv to ./echopype/test_data/ek60/fhdjkflha.nc
		e_data = EchoData(nc_path)
		e_data.calibrate(save=True, save_postfix='_SvNew')
		08:23:31  saving calibrated Sv to ./echopype/test_data/ek60/DY1801_EK60-D20180211-T164025_SvNew.nc
		e_data = EchoData(nc_path)
		e_data.calibrate(save=True, save_postfix='_SvNew', save_path='./echopype/test_data/ek60/forceoverwirte.nc')
		08:23:44  saving calibrated Sv to ./echopype/test_data/ek60/forceoverwirte.nc
		```

## 2020-02-17
- [x] require user to specify Sv files to use for MVBS data, or calibrate and calculate MVBS


- [ ] add testing for converting to multiple files, specified paths combinations
- [ ] add testing for specifying Sv source for MVBS, etc


- **[BUG]** notice a behavior if running first `tmp = Convert(LIST_OF_FILE)` and convert into individual files by running `tmp.raw2nc()`, and then call `tmp.raw2nc(combine=True, save_path=COMBINED_FILENAME)`, the conversion will only be on the first file and no printout (converting files: xxxxx) will happen --> this seems to be a bug related to how the internal filenames handling works when the Convert object is reused. If running `tmp.raw2nc(combine=True, save_path=COMBINED_FILENAME)` first and then `tmp.raw2nc()`, the first converted individual file will contain the combined data, but the second individual file will be normal and only contain data from the second file.
- verified that `overwrite=True` works for both individual file conversion and combined file conversion


## 2020-02-25
- [x] add [EK60 documentation](https://www.simrad.net/ek60_ref_english/default.htm) into docs
- [x] update sample_thickness, sound speed, absorption updates are correctly set up as data array with coordinates attached


## 2020-03-28
Code readability and logic comments for Kavin:
- It is not a good practice to initialize variables outside of `__init__()` : `self._append_zarr`, `self._temp_path`
- line 455-467: these should be absorbed into convert/convertbase/validate_path(), this will also remove redundancy in convert/azfp.py
- right now the conversion and how those are implemented are too much "on the fly", the code logic can be improved
	- `export()` should be outside of `save()` for readability
	- the various set_group subfunctions should also be moved out. I can see having top_level, provenance, env, and sonar set in 1 function, and NMEA, beam, and platform in another; it is good that you have the zarr appending component already in the set_groups util functions
	- let's move the calculation of abs_val, ss_val to within `_set_env_dict()`
	- you should not call `__init__` internally in other functions, this will make debugging very difficult
- The flow should be cleaner and easy to follow:
	- `validate_path()` should take care of ALL the creation and validation of filenames and temp folder, etc. Note the initialization issue above.
	- determine if this is a zarr appending case early on, so you don't do it among all the file unpacking and saving operations
	- clean up code logic: line 490-491 actually won't happen
	- the `save()` function should have a clean structure:
	 	- move what you have in line 455-467 into `save()` so that these important condition checks are not hidden to someone reading your code
		- don't use `self._append_zarr` but just have it as a variable `append_zarr`. Is there a reason why it has to be in the object attributes? it is only passed into `SetGroups`
		- using `validate_path()` multiple times is confusing: this can be avoided once you have all the path/filename handling in `validate_path()` as suggested above. Also make sure you comment code extensively: I didn't understand why you call it twice until looking into the detailed implementation
		- you should not call `__init__` internally in other functions, this will make debugging very difficult. Instead, you should explicitly reset specific attributes that need to be reset (What are those?)
		- for something like line 537, you should comment why you only do combine_files for ek60 by saying that zarr file combinations are taken care of by appending new data as you read each individual files
		- does the current flow work if you have 10 files to be combined, and file 6-10 have different range and need to be split into another file?
- others:
	- the entire nmea group is copied for all range-split files: some data are redundant?



## 2020-03-30
- Git LFS setup using BFG tools

- remove raw files
	```~shell
	Deleted files
	-------------

		Filename                            Git id           
		-----------------------------------------------------
		2015843-D20151023-T190636.raw     | 54680eb0 (134 B)
		DY1801_EK60-D20180211-T164025.raw | aef5dbe5 (1.2 MB)
	```

- remove nc files
	```~shell
	Deleted files
	-------------

		Filename                                 Git id                                
		-------------------------------------------------------------------------------
		17082117.nc                            | ccc43a17 (19.6 MB)                    
		17082117_Sv.nc                         | 5794b113 (19.4 MB)                    
		17082117_TS.nc                         | 3eaeaaf7 (19.4 MB)                    
		DY1801_EK60-D20180211-T164025_Sv_TS.nc | 0880516b (6.7 MB), e0d5a7ea (4.5 MB)  
		azfp_test.nc                           | ccc43a17 (19.6 MB), 81629c66 (19.5 MB)
		test.nc                                | 3f1b569e (41.2 KB)                    
		test2.nc                               | 1f32f4a4 (96 B)                       
		test3.nc                               | 7617ff97 (7.7 KB)                     
	```

- remove 01A files:
	```~shell
	% java -jar bfg-1.13.0.jar --delete-files "*.01A" ~/code_git/echopype-lfs-test

	Deleted files
	-------------

		Filename       Git id           
		--------------------------------
		17031001.01A | f289ac1a (2.5 MB)
		17082117.01A | 32379fc7 (4.9 MB)
		18030100.01A | 653add3e (4.9 MB)
	```

- All files >1MB
	```
	% java -jar bfg-1.13.0.jar --strip-blobs-bigger-than 1M ~/code_git/echopype-lfs-test

	Deleted files
	-------------

		Filename                                                Git id                                    
		--------------------------------------------------------------------------------------------------
		17031001.01A                                          | f289ac1a (2.5 MB)                         
		17082117.01A                                          | 32379fc7 (4.9 MB)                         
		17082117.nc                                           | ccc43a17 (19.6 MB)                        
		17082117_Sv.nc                                        | 5794b113 (19.4 MB)                        
		17082117_TS.nc                                        | 3eaeaaf7 (19.4 MB)                        
		18030100.01A                                          | 653add3e (4.9 MB)                         
		18030100.01a                                          | 653add3e (4.9 MB)                         
		18030100.png                                          | d38c7e3b (1.1 MB)                         
		DY1801_EK60-D20180211-T164025.raw                     | aef5dbe5 (1.2 MB)                         
		DY1801_EK60-D20180211-T164025_Sv_TS.nc                | 0880516b (6.7 MB), e0d5a7ea (4.5 MB)      
		azfp_demo.ipynb                                       | 34acbb84 (2.3 MB)                         
		azfp_test.nc                                          | ccc43a17 (19.6 MB), 81629c66 (19.5 MB)    
		develop_class_EchoDataRaw.ipynb                       | 3fe5a34d (2.2 MB), a7b5ccd6 (1.3 MB)      
		environment.pickle                                    | 47501de7 (1.5 MB), 7f721b0b (1.5 MB), ...
		new plot test.ipynb                                   | a9cbd2f8 (9.3 MB), 0ebb7a75 (11.4 MB), ...
	```

- [Git LFS tutorial wiki](https://github.com/git-lfs/git-lfs/wiki/Tutorial)
- [Best practice for migrating an existing Git repo to support LFS?](https://github.com/git-lfs/git-lfs/issues/326): discussions on the paths to rewrite or not rewriting history, seems prior to `git lfs migrate`
- [what does git lfs migrate do](https://stackoverflow.com/questions/51782043/what-does-git-lfs-migrate-do): some investigations on what files are created by `git lfs migrate`


- [git lfs push --all fails with "open /FileRemovedInEarlierCommit.png: no such file or directory"](https://github.com/git-lfs/git-lfs/issues/1113)
- [after git lfs migrate: âUnable to find source for objectâ when trying to push everything](https://github.com/git-lfs/git-lfs/issues/3923)
- [LFS upload failed: missing](https://github.com/git-lfs/git-lfs/issues/2446): the fixes didn't work for me and I ended up using BFG-repo-cleaner to remove references of that missing file


cache:
  - .git/lfs


## 2020-06-23
- parsing EK80 XML:
	- 'Version' under 'Transceiver' node is converted to transceiver_version --> ideally should be saved into vendor specific group to preserve all info from raw data
	```python
	self.transceiver_parsing_options
	Out[11]:
	{'TransceiverNumber': [int, '', ''],
	 'Version': [str, 'transceiver_version', ''],
	 'IPAddress': [str, 'ip_address', ''],
	 'Impedance': [int, '', '']}
	```

	```python
	data['configuration'][channel_id]
Out[12]:
{'transceiver_name': 'WBT 549762',
 'ethernet_address': '009072086382',
 'ip_address': '157.237.15.100',
 'transceiver_version': '[0] Ethernet: 00:90:72:08:63:82\r\n[1] Parts-list: WBT 371790/D\r\n[2] Product: WBT\r\nIP Address: 157.237.15.100\r\nSubnet mask:: 255.255.0.0\r\nDefault gateway: 157.237.15.1\r\nSerial number: 549762\r\nEmbedded software: Rev. 2.16\r\nFPGA TX firmware: Rev. 4\r\nFPGA RX firmware: Rev. 7\r\nCH1: 520W CH2: 508W CH3: 499W CH4: 504W\r\nTRD1: Unable to detect transducer\r\nTRD2: Unable to detect transducer\r\nTRD3: Unable to detect transducer\r\nTRD4: Unable to detect transducer\r\n',
 'transceiver_software_version': '2.16',
 'transceiver_number': 1,
 'market_segment': 'Scientific',
 'transceiver_type': 'WBT',
 'serial_number': '549762',
 'impedance': 5400}
	```
	- under the 'Channels' node under a given transceiver:
	```python
	parse_opts
	Out[13]:
	{'MaxTxPowerTransceiver': [int, '', ''],
	 'PulseDuration': [float, '', ';'],
	 'PulseDurationFM': [float, 'pulse_duration_fm', ';'],
	 'SampleInterval': [float, '', ';'],
	 'ChannelID': [str, 'channel_id', ''],
	 'HWChannelConfiguration': [str, 'hw_channel_configuration', '']}
	```

	after dict_to_dict the below is added to data['configuration'][channel_id]
	```python
	data['configuration'][channel_id]
	Out[14]:
	{'transceiver_name': 'WBT 549762',
	 'ethernet_address': '009072086382',
	 'ip_address': '157.237.15.100',
	 'transceiver_version': '[0] Ethernet: 00:90:72:08:63:82\r\n[1] Parts-list: WBT 371790/D\r\n[2] Product: WBT\r\nIP Address: 157.237.15.100\r\nSubnet mask:: 255.255.0.0\r\nDefault gateway: 157.237.15.1\r\nSerial number: 549762\r\nEmbedded software: Rev. 2.16\r\nFPGA TX firmware: Rev. 4\r\nFPGA RX firmware: Rev. 7\r\nCH1: 520W CH2: 508W CH3: 499W CH4: 504W\r\nTRD1: Unable to detect transducer\r\nTRD2: Unable to detect transducer\r\nTRD3: Unable to detect transducer\r\nTRD4: Unable to detect transducer\r\n',
	 'transceiver_software_version': '2.16',
	 'transceiver_number': 1,
	 'market_segment': 'Scientific',
	 'transceiver_type': 'WBT',
	 'serial_number': '549762',
	 'impedance': 5400,
	 'channel_id': 'WBT 549762-15 ES70-7C',
	 'channel_id_short': 'ES70-7C Serial No: 0',
	 'max_tx_power_transceiver': 2000,
	 'pulse_duration': [0.000128, 0.000256, 0.000512, 0.001024, 0.002048],
	 'pulse_duration_fm': [0.000512, 0.001024, 0.002048, 0.004096, 0.008192],
	 'hw_channel_configuration': '15'}
	```

	- after parsing the 'Transducer' section under a given transceiver and a given channel:
	```python
	data['configuration'][channel_id]
	Out[18]:
	{'transceiver_name': 'WBT 549762',
	 'ethernet_address': '009072086382',
	 'ip_address': '157.237.15.100',
	 'transceiver_version': '[0] Ethernet: 00:90:72:08:63:82\r\n[1] Parts-list: WBT 371790/D\r\n[2] Product: WBT\r\nIP Address: 157.237.15.100\r\nSubnet mask:: 255.255.0.0\r\nDefault gateway: 157.237.15.1\r\nSerial number: 549762\r\nEmbedded software: Rev. 2.16\r\nFPGA TX firmware: Rev. 4\r\nFPGA RX firmware: Rev. 7\r\nCH1: 520W CH2: 508W CH3: 499W CH4: 504W\r\nTRD1: Unable to detect transducer\r\nTRD2: Unable to detect transducer\r\nTRD3: Unable to detect transducer\r\nTRD4: Unable to detect transducer\r\n',
	 'transceiver_software_version': '2.16',
	 'transceiver_number': 1,
	 'market_segment': 'Scientific',
	 'transceiver_type': 'WBT',
	 'serial_number': '549762',
	 'impedance': 5400,
	 'channel_id': 'WBT 549762-15 ES70-7C',
	 'channel_id_short': 'ES70-7C Serial No: 0',
	 'max_tx_power_transceiver': 2000,
	 'pulse_duration': [0.000128, 0.000256, 0.000512, 0.001024, 0.002048],
	 'pulse_duration_fm': [0.000512, 0.001024, 0.002048, 0.004096, 0.008192],
	 'hw_channel_configuration': '15',
	 'transducer_name': 'ES70-7C',
	 'transducer_serial_number': '0',
	 'transducer_frequency': 70000.0,
	 'transducer_frequency_minimum': 45000.0,
	 'transducer_frequency_maximum': 90000.0,
	 'transducer_beam_type': 1,
	 'equivalent_beam_angle': -20.7,
	 'gain': [27.0, 27.0, 27.0, 27.0, 27.0],
	 'sa_correction': [0.0, 0.0, 0.0, 0.0, 0.0],
	 'max_tx_power_transducer': 750.0,
	 'beam_width_alongship': 7.0,
	 'beam_width_athwartship': 7.0,
	 'angle_sensitivity_alongship': 23.0,
	 'angle_sensitivity_athwartship': 23.0,
	 'angle_offset_alongship': 0.0,
	 'angle_offset_athwartship': 0.0,
	 'directivity_drop_at_2x_beam_width': 0.0}
	```
	- info in 'Header' node:
	```python
	h.attrib
	Out[24]:
	{'Copyright': 'Copyright(c) Kongsberg Maritime AS, Norway',
	 'ApplicationName': 'EK80',
	 'Version': '1.10.3.0',
	 'FileFormatVersion': '1.20',
	 'TimeBias': '0'}
	```

- for WBT, under a given transceiver there is only 1 channel, and each channel is connected to 1 transducer
- for WBT mini, under a given transceiver there could be 2 channels, each connect to 1 transducer (@emlyndavis file)
- for regular transducers, under a given transceiver, each channel will have their own transducer node
- for 2-in-1 transducer, under a given transceiver, channel 1 will have a transducer node but channel doesn't have a transducer node (@FletcherFT file)


## 2020-06-24
- `TransducerName` appears to be unique under 'Transceivers'-'Transceiver'-'Channels'-'Channel'-'Transducer' and 'Transducers'-'Transducer'
- `SerialNumber` appears to be unique under 'Transceivers'-'Transceiver'-'Channels'-'Channel'-'Transducer' and 'Transducers'-'Transducer'

Under the 'Transceivers'-'Channels' node, there are 3 pieces of critical info for each channel:
- 'TransducerName'="ES200-7CDK-Split"
- may be a good idea to record the entire configuration datagram into the vendor specific group? --> will be resolved once #179 is merged.


## 2020-07-29
- Start thinking about how to structure the visualization subpackage:
	- use cases: people parsed 1 or multiple files
		- want to visualize the raw echo data (stored in `backscatter_r`)
		- continue to calibrate to produce Sv
			- want to visualize Sv
			- continue to compute MVBS
				- want to visualize MVBS


## CRITICAL TODO:
- Check what's going on with EK60 data GPS trajectory from hake survey
- Fix OOI file location




## 2020-08-17 to 2020-08-21

### Re-design data conversion class
- see `class_design.md`, but note that some part of the design there was changed when implemented in pseudo code form
- the latest design is in:
	- `converbase_new.py`
	- `setgroups_new.py`
	- `convert_ui.py`
- one important decision Kavin and I made was to **pad NaNs of the shorter pings** instead of splitting a file based on changes in `range_bin`



## 2020-08-22

### Look into EK80 datagrams
- added below to _read_datagrams() to check datagram sequences:
	```python
	# storage variables
	datagram_type_all = []
	sub_datagram_type_all = []
	datagram_time_all = []

	# For figuring out datagram transition
	datagram_time_all.append(new_datagram['timestamp'])
	datagram_type_all.append(new_datagram['type'])
	if new_datagram['type'].startswith("XML"):
		sub_datagram_type_all.append(new_datagram['subtype'])
	else:
		sub_datagram_type_all.append(None)
	```
- consists of the following types of datagrams:
	- `XML-environment`, `XML-parameter`, `FIL`, `NME`, `RAW3`, `MRU`
	- each file has `FIL` datagrams in the beginning
	- `XML-parameter` and `RAW3` come in pairs
	- `NME` and `MRU` datagrams are interleaved among the `XML-parameter` and `RAW3` combinations
- each file appears to only have one environment data datagram (`XML-environment`)
- each `RAW3` datagram is preceded by a `XML-parameter` datagram
- saved the datagram sequence in to csv files:
	- bb file: `D20170912-T234910_datagram_seq.csv`
	- cw file: `D20190822-T161221_datagram_seq.csv`
- what to check for change of tx parameters?
	```python
	# this is one of the parameter datagram (XML-parameter) from the BB mode test file
	{'channel_id': 'WBT 545612-15 ES200-7C',
	 'channel_mode': 0,
	 'pulse_form': 1,
	 'frequency_start': '160000',
	 'frequency_end': '260000',
	 'pulse_duration': 0.001024,
	 'sample_interval': 5.33333333333333e-06,
	 'transmit_power': 15.0,
	 'slope': 0.01220703125}

	# this is a sample XML-environment from the BB mode test file
	{'type': 'XML0',
	'low_date': 3137819385,
	'high_date': 30616609,
	'timestamp': numpy.datetime64('2017-09-12T23:49:10.723'),
	'bytes_read': 448,
	'subtype': 'environment',
	'environment': {'depth': 240.0,
	'acidity': 8.0,
	'salinity': 33.7,
	'sound_speed': 1486.4,
	'temperature': 6.9,
	'latitude': 45.0,
	'sound_velocity_profile': [1.0, 1486.4, 1000.0, 1486.4],
	'sound_velocity_source': 'Manual',
	'drop_keel_offset': 0.0,
	'drop_keel_offset_is_manual': 0,
	'water_level_draft': 0.0,
	'water_level_draft_is_manual': 0,
	'transducer_name': 'Unknown',
	'transducer_sound_speed': 1490.0},
	'xml': '<?xml version="1.0" encoding="utf-8"?>\r\n<Environment Depth="240" Acidity="8" Salinity="33.7" SoundSpeed="1486.4" Temperature="6.9" Latitude="45" SoundVelocityProfile="1.000000;1486.400000;1000.000000;1486.400000" SoundVelocitySource="Manual" DropKeelOffset="0" DropKeelOffsetIsManual="0" WaterLevelDraft="0" WaterLevelDraftIsManual="0">\r\n  <Transducer TransducerName="Unknown" SoundSpeed="1490" />\r\n</Environment>'}
	```

### Look into EK60 datagrams
- saved the datagram sequence in to csv files:
	- `DY1801_EK60-D20180211-T164025_datagram_seq.csv`
	- only consists of `RAW0` and `NME0` datagrams
- what to check for change of tx and environment parameters?
	```python
	# this is a sample RAW0 datagram
	{'type': 'RAW0',
	'low_date': 71406392,
	'high_date': 30647127,
	'channel': 1,
	'mode': 3,
	'transducer_depth': 9.149999618530273,
	'frequency': 18000.0,
	'transmit_power': 2000.0,
	'pulse_length': 0.0010239999974146485,
	'bandwidth': 1573.66552734375,
	'sample_interval': 0.00025599999935366213,
	'sound_velocity': 1466.0,
	'absorption_coefficient': 0.0030043544247746468,
	'heave': 0.0,
	'roll': 0.0,
	'pitch': 0.0,
	'temperature': 4.0,
	'heading': 0.0,
	'transmit_mode': 1,
	'spare0': '\x00\x00\x00\x00\x00\x00',
	'offset': 0,
	'count': 1386,
	'timestamp': numpy.datetime64('2018-02-11T16:40:25.276'),
	'bytes_read': 5648,
	'power': array([ -6876,  -8726, -11086, ..., -11913, -12522, -11799], dtype=int16),	
	'angle': array([[ 110,   13],
        [   3,   -4],
        [ -54,  -65],
        ...,
        [ -92, -107],
        [-104, -122],
        [  82,   74]], dtype=int8)}
	```
- tx parameters to check include: 
	- transmit_power
	- pulse_length
	- bandwidth
	- sample_interval
	- transmit_mod (# 0 = Active, 1 = Passive, 2 = Test, -1 = Unknown)
	- offset
- env parameters to check include:
	- sound_velocity
	- absorption_coefficient
	- temperature







- example files:
	- `D20190508-T015545.raw`: only 1 frequency channel
	- `cr1857-D20120330-T182952.raw`: different sample_interval for different frequency channels
	- `cr2061-D20141020-T024010.raw`: change range_bin length in the middle of the file
- [x] allow specifying folder to save Sv and MVBS to
- [x] allow user to specify overwriting the already converted nc file
- [ ] run a series of test files
- [x] EK60 RAW0 angle parsing seems wrong? need incrementing indx? *--> it is correctly implemented*
- [x] check python output against EchoView output: pay attention if there is an extra ping in the beginning that EV is not exported if set to "geo-references power" but is exported if just exporting "power" *--> for the BB test data set, the first ping is not geo-referenced*
- [x] check location_time and lat/lon are parsed and stored correctly.
- [x] use `map` instead of `groupby-apply` to implement noise removal
- [x] make the data variable in Sv_clean also `Sv`, so that `get_MVBS` can just use the same variable name
- [x] add `conda create -c conda-forge -n echopype python=3.8  --file requirements.txt` to installation instruction to make sure people know to you py38, due to zarr+numcodecs problem
- [x] revert zarr to use older version (maybe 2.3.1) to avoid wheel problem with numcodecs 0.6.4 on Mac and Windows (seems that zarr==2.3.2 requires numcodecs==0.6.4, but earlier the numcodecs version wasn't specified in the requirements) *--> not needed anymore if use python==3.8*
- [x] implement TS calculation for EK60
- [x] add option for users to save `_Sv` and `_Sv_clean` and `_MVBS` to a specified folder (default is the same folder as the original data file.)
- [ ] add in documentation on what type of range_bin change is handled by the code at the moment
- [ ] allow MVBS calculation using the actual ping_time as well as ping number index
- [ ] add source files used to calculate MVBS in the output MVBS file
- [ ] update noise_est = e_data.noise_estimates() as the test currently fails in test_ek60_model.py:28
- [ ] model.ek60.calc_range needs flag to change source of sound speed (when calling recalculate_environment)
- [ ] in recalculate_environment for self.calc_sound_speed, need to call uwa.calc_sound_speed based on sonar type
- [ ] figure out how to not have separate self.nc_path and self.zarr_path since we already have self.save_path
- [ ] add conversion from electrical angle to physical angle
- [x] find a place to store `channel_id` (something like `WBT 549762-15 ES70-7C`) *--> already in the Beam group*
- [ ] find out the orientation of the quadrants
- [x] multiple file conversion for AZFP
- [ ] change EK60 filename parsing back to using regex
- [ ] change command line converter to use click
- [ ] Overusing lists and for loops. A lot of the operations you have that first create an empty list, append new values, create another list, and then append new values when transferring from `self.parameters` to `beam_dict` can be dramatically simplified if you have numpy arrays in self.parameters and then just use indexing/slicing. I changed a lot of these in the commits yesterday for ek60 code, pls take a look and change accordingly.



This minor release includes the following:
- fix the bug in remove_noise function for AZFP data (issue #110)
- update testing to use both python 3.7 and 3.8
- include how to pull test files using git LFS in documentation
- remove a stalled command line file converter that won't be further developed


re.compile('(?P<survey>\w+)?-?D(?P<date>\w{1,8})-T(?P<time>\w{1,6})-?(?P<postfix>\w+)?.raw')





## Meeting with Dax/Tim about OOICloud
- staging.ooi.pangeo.io


## Meeting with Emilio/Scott/Anthony about Pangeo demo
- connecting with MURR SST data set (connect with NASA context) 
- scalable computing -- dask
- 1 notebook: data transformation
- 1 notebook: data overlaid with SST, visualization
- rough estimates on time: by August 2021. quarterly updates


## Meeting with Emilio about Pangeo demo
Meeting with Emilio:
- add NCEI and anthony and scott to the pangeo_echopype_test
- notebook 1: 
	- data transformation
	- re-affirm the value of a community standard
	- value of zarr (SONAR-netCDF4 in zarr)
	- improvements of echopype:
		- I/O stream to zarr directly (Don added)
		- ability to write directly (Kavin added)
		- check convention: start documenting in the docs and pangeo demo
		- testing for combining files
		- dask: how to showcase the computing power --> Emilio will arrange call with Scott
		- whether have access to dask gateway when installing echopype from notebook
- notebook 2: 
	- data overlaid with SST
	- visualization (panel, showcase use of zarr/dask)


- calibration curves in the tranducer XML not currenlty saved
- ping_time repetition, potential reversal can be dealt _after_ the zarr stage
- take a look at what's going on with the EK80 example files


## Echopype code review with Kavin
- Your code is brittle
- Having code "work" is not good enough: 
	you have been working on this codebase for a long time, 
	and I expect you to:
	- be able to do TOP-DOWN organization of code and approach, 
	- factor out functions when needed,
	- do variable initialization and docstring properly,
	instead of just patching things up.
- Be careful and always test code
	- errors like looping but not actually using the looped variables
	- typos in comments and code
- variable name shadowing: review your scope understanding
- breaking object oriented code
- Think what is readable and meaningful when you make variable and function names 
- Lack of follow up: I cannot chase after you for each single change
- Check your logic for your if-else


- `frequency_start` and `frequency_end` are currently encoded as coordinates, they should be attributes
- `sa_correction` should not be encoded for EK80 BB data
- try-exception whether it incurs computational resources
- pulse compression output:
	- drop coordinates `frequency` after pulse compression
	- the output of pulse compression has one dimension not attached: range_bin
	- the new `compress` implementation: did you test the performance gain using dask?
- Calibration parameters
	- EK60 cal params are already in the Beam group
	- EK80 cal params are in the config XML: need to decide where to save it
- revise the sa_correcton and gain look up table to use the closest pulse duration
- you really should stop using simple letters as index, especially i
- you should avoid using direct index without specifying the dimension when indexing xarray dataarray: e.g., ds_beam.slope[:,0]: it is confusing and difficult to debug.



## Echopype code changes / notes
- `sample_interval` = 1.5e6/wbt_decimator_factor/pc_decimation_factor
- for EK power data: 
	```python
	# Manufacturer-specific power conversion factor
	INDEX2POWER = (10.0 * np.log10(2.0) / 256.0)
	```
- Removed data variable from EK80 set_beam:
	- non_quantitative_processing
	- sample_time_offset
	- transmit_bandwidth



- NCEI zarr gitbook from Rudy
https://cires.gitbook.io/zarr/






- **Things to bring up to Kavin**:
  - always check your output before send results or say it's ready to others: readibility, reliability
    - problems in pressure retrieval and click detection saved to numpy
    - how would I know what your click detection results are?
    - always rerun your notebook after finishing work and before commit
    - your commits had: "add sv and ts calibration for all echosounders" on Nov 25 and I expected them to work almost a month after that
    - ECHOPYPE related:
      - `_check_key_param_consistency()` is not a static method and not a class method. What is it? Go read about how to define decorators within a class
      - EchoData descriptor:
        - input params not used in EchoData: have some check in place for the inputs?
        - 4 lines of "Data has not been calibrated. Call `Process.calibrate(EchoData)` to calibrate." are printed out when I initialize an EchoData object. Some logic has to be workedo ut.
      - why is `validate_proc_path` in `io` when you only use it in `Process`? We talked about this last time.

  - increase your productivity
    - I added all design for Process on Nov 24
  - time planned to take off over Christmas break




## 2020/12/31
### Plan for echopype overhaul
- global changes needed:
	- remove io._print warning method, we don't need another layer of abstraction
	- all `_cw` stuff should become `_powerangle` since the difference is in the data type (complex vs power/angle instead of the signal type (BB vs CW)
- consider using black to make style consistent







# Refs for manuscript
- [GliderTool: GliderTools: A Python Toolbox for Processing Underwater Glider Data](https://www.frontiersin.org/articles/10.3389/fmars.2019.00738/full)



- Dask gateway HTTPS server, S3: 
	- should be fairly straightforward to parallelize
- how to always be synced to the base environment
	- Don has created custom docker image
	- if do not want to build your own images: 
		- https://github.com/pangeo-data/pangeo/pull/792#issuecomment-727132517
		- https://pangeo.io/cloud.html#dask-software-environment
- don't move to dask gateway unless it is taking far too long
- 10-100 MB per chunk
- re-chunk when combine
- s3://ooi-raw-data/CE04OSPS-PC01B-05-ZPLSCB102
- rechunker: https://github.com/pangeo-data/rechunker
	- consider storing one for spatial and tempo
- xarray issue: 
	- indices that would be slower when specifying coordinate
	- 




